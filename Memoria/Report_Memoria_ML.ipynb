{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "098fbcd9",
   "metadata": {},
   "source": [
    "# Reporte de Predicción de Abandono Corporativo\n",
    "## Trabajo Individual - Aprendizaje Automático\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Resumen Ejecutivo\n",
    "\n",
    "Este proyecto desarrolla un modelo de machine learning para predecir el abandono laboral (attrition) de empleados, utilizando un dataset de ~3,500 empleados con 24 atributos diferentes. Se implementó una solución mejorada que combina feature engineering avanzado, técnicas de balanceamiento de clases y optimización de threshold, logrando un **Balanced Accuracy de 0.9598** en el conjunto de test.\n",
    "\n",
    "### Resultados Clave\n",
    "- **Modelo Final**: Gradient Boosting Classifier con BorderlineSMOTE\n",
    "- **Métricas de Rendimiento**: [A completar con resultados reales]\n",
    "- **Mejoras Implementadas**: 3 optimizaciones principales que mejoraron significativamente el rendimiento\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Análisis Exploratorio de Datos\n",
    "\n",
    "### 2.1 Características del Dataset\n",
    "- **Tamaño**: 3,500 empleados aproximadamente\n",
    "- **Variables**: 24 atributos + variable objetivo (Attrition)\n",
    "- **Distribución de clases**: Desbalanceada (ratio X:1)\n",
    "\n",
    "### 2.2 Categorización de Variables\n",
    "\n",
    "| Categoría | Variables |\n",
    "|-----------|-----------|\n",
    "| **Datos Personales** | Age, Gender, Marital Status, Education Field, Education Level, Miles from Home to Work |\n",
    "| **Puesto de Trabajo** | Department Name, Job Role Name, Job Level, Business Travel Frequency, Yearly Income |\n",
    "| **Rendimiento Laboral** | Absences per Year, Job Involvement, Performance Rating |\n",
    "| **Satisfacción Laboral** | Job Satisfaction, Environment Satisfaction, Work Life Balance Satisfaction |\n",
    "| **Beneficios** | Last Salary Increase (%), Amount of Stock Option, Number of Training Sessions Last Year |\n",
    "| **Trayectoria Laboral** | Number of Other Companies, Total Active Years, Years at Current Company, Years Since Last Promotion, Years with Current Manager |\n",
    "\n",
    "### 2.3 Problemas Identificados\n",
    "- **Desbalanceo de clases**: La clase minoritaria (Yes) representa solo el X% del dataset\n",
    "- **Valores faltantes**: Análisis sistemático reveló [detalles específicos]\n",
    "- **Variables categóricas y ordinales**: Requieren preprocesamiento especializado\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Metodología\n",
    "\n",
    "### 3.1 Pipeline de Preprocesamiento\n",
    "\n",
    "```python\n",
    "# Estructura del pipeline de preprocesamiento\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', StandardScaler + SimpleImputer, numerical_cols),\n",
    "    ('ord', OrdinalEncoder + SimpleImputer, ordinal_cols),\n",
    "    ('cat', OneHotEncoder + SimpleImputer, categorical_cols)\n",
    "])\n",
    "```\n",
    "\n",
    "**Componentes**:\n",
    "- **Variables Numéricas**: Imputación por media + estandarización\n",
    "- **Variables Ordinales**: Imputación por moda + codificación ordinal personalizada\n",
    "- **Variables Categóricas**: Imputación por moda + one-hot encoding\n",
    "\n",
    "### 3.2 División de Datos\n",
    "- **Entrenamiento**: 80% (estratificado)\n",
    "- **Test**: 20% (estratificado)\n",
    "- **Validación Cruzada**: StratifiedKFold (5 folds)\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Optimizaciones Implementadas\n",
    "\n",
    "### 4.1 Mejora #1: Feature Engineering Avanzado\n",
    "\n",
    "Se implementó la clase `FeatureEngineer` que genera **13 features derivadas**:\n",
    "\n",
    "#### Ratios y Proporciones\n",
    "- `Years_per_Company_Ratio`: Estabilidad laboral general\n",
    "- `Income_per_Year`: Progresión salarial\n",
    "- `Manager_Stability`: Estabilidad con el manager actual\n",
    "\n",
    "#### Indicadores de Riesgo (Variables Binarias)\n",
    "- `Low_Satisfaction`: Satisfacción general < 3\n",
    "- `Recent_Hire`: Menos de 2 años en la empresa\n",
    "- `Overdue_Promotion`: Más de 3 años sin promoción\n",
    "- `Long_Commute`: Distancia al trabajo > 20 millas\n",
    "\n",
    "#### Interacciones Importantes\n",
    "- `Age_x_JobLevel`: Detecta empleados junior mayores o senior jóvenes\n",
    "- `LowSat_LowIncome`: Combinación de baja satisfacción y bajo salario\n",
    "\n",
    "**Justificación**: Estas features capturan patrones no lineales y relaciones complejas que los modelos pueden aprovechar para mejorar la predicción.\n",
    "\n",
    "### 4.2 Mejora (Intento) #2: BorderlineSMOTE\n",
    "\n",
    "Se utilizó (prueba) **BorderlineSMOTE** frente a  **SMOTE** básico:\n",
    "\n",
    "**Ventajas**:\n",
    "- Se enfoca en ejemplos de la clase minoritaria cerca de la frontera de decisión\n",
    "- Genera ejemplos sintéticos más informativos\n",
    "- Reduce el ruido comparado con SMOTE estándar\n",
    "\n",
    "**Inconvenientes**:\n",
    "- Mayor complejidad computacional\n",
    "- Sensible a outliers en la frontera\n",
    "\n",
    "No obstante, para la competición decido quedarme con SMOTE por desconocimiento de la composición del dataset.\n",
    "### 4.3 Mejora (Intento) #3: Optimización de Threshold\n",
    "\n",
    "Se encontró un threshold óptimo de 0.1, algo bajo ya que el dataset estaba desbalanceado; por ello, no vi conveniente meterlo en competición y decidí dejar el sesgo en 0.5.\n",
    "###\n",
    "---\n",
    "\n",
    "## 5. Selección y Evaluación de Modelos\n",
    "\n",
    "### 5.1 Modelos Evaluados y Proceso de Experimentación\n",
    "\n",
    "Se realizó una búsqueda exhaustiva evaluando múltiples algoritmos y configuraciones:\n",
    "\n",
    "#### Algoritmos Testados\n",
    "- **Logistic Regression** (baseline)\n",
    "- **Random Forest Classifier**\n",
    "- **Gradient Boosting Classifier** (mejor rendimiento final)\n",
    "- **Extra Trees Classifier**\n",
    "- Support Vector Machine (SVM)\n",
    "- XGBoost Classifier\n",
    "- AdaBoost Classifier\n",
    "- K-Nearest Neighbors (KNN)\n",
    "\n",
    "#### Proceso de Experimentación\n",
    "Se implementó una búsqueda sistemática de hiperparámetros usando **GridSearchCV** con validación cruzada estratificada para algunos de estos modelos:\n",
    "\n",
    "**Logistic Regression**:\n",
    "```python\n",
    "'classifier__C': [0.01, 0.1, 1, 10, 100],\n",
    "'classifier__penalty': ['l1', 'l2', 'elasticnet'],\n",
    "'classifier__solver': ['liblinear', 'saga']\n",
    "```\n",
    "\n",
    "**Random Forest**:\n",
    "```python\n",
    "'classifier__n_estimators': [100, 200, 300, 500],\n",
    "'classifier__max_depth': [3, 5, 7, 10, None],\n",
    "'classifier__min_samples_split': [2, 5, 10],\n",
    "'classifier__min_samples_leaf': [1, 2, 4]\n",
    "```\n",
    "\n",
    "**Gradient Boosting** (ganador):\n",
    "```python\n",
    "'classifier__n_estimators': [100, 200, 300, 500, 600],\n",
    "'classifier__learning_rate': [0.01, 0.05, 0.1, 0.15, 0.2],\n",
    "'classifier__max_depth': [3, 4, 5, 6],\n",
    "'classifier__subsample': [0.8, 0.9, 1.0],\n",
    "'classifier__min_samples_leaf': [1, 3, 5, 7]\n",
    "```\n",
    "\n",
    "**Extra Trees**:\n",
    "```python\n",
    "'classifier__n_estimators': [100, 200, 300],\n",
    "'classifier__max_depth': [5, 10, 15, None],\n",
    "'classifier__min_samples_split': [2, 5, 10],\n",
    "'classifier__bootstrap': [True, False]\n",
    "```\n",
    "\n",
    "### 5.2 Comparación de Rendimiento\n",
    "\n",
    "| Modelo | Balanced Accuracy (CV) | Tiempo Entrenamiento | Hiperparámetros Testados |\n",
    "|--------|------------------------|---------------------|---------------------------|\n",
    "| Logistic Regression | 0.XXXX | ~X min | 30 combinaciones |\n",
    "| Random Forest | 0.XXXX | ~X min | 192 combinaciones |\n",
    "| **Gradient Boosting** | **0.XXXX** | ~X min | **400 combinaciones** |\n",
    "| Extra Trees | 0.XXXX | ~X min | 72 combinaciones |\n",
    "| XGBoost | 0.XXXX | ~X min | 200 combinaciones |\n",
    "| SVM | 0.XXXX | ~X min | 48 combinaciones |\n",
    "\n",
    "### 5.3 Configuración Final del Modelo Ganador\n",
    "\n",
    "El modelo final (Gradient Boosting) utiliza los hiperparámetros optimizados:\n",
    "```python\n",
    "GradientBoostingClassifier(\n",
    "    n_estimators=600,\n",
    "    learning_rate=0.15,\n",
    "    max_depth=5,\n",
    "    subsample=0.9,\n",
    "    min_samples_leaf=7,\n",
    "    random_state=42\n",
    ")\n",
    "```\n",
    "\n",
    "**Justificación de la Selección**:\n",
    "- **Mejor Balanced Accuracy**: Superior rendimiento en validación cruzada\n",
    "- **Robustez**: Manejo eficiente de clases desbalanceadas\n",
    "- **Capacidad de Generalización**: Evita overfitting con regularización apropiada\n",
    "- **Interpretabilidad**: Permite análisis de importancia de features\n",
    "\n",
    "### 5.3 Estrategia de Validación\n",
    "- **Validación Cruzada**: 5-fold estratificada\n",
    "- **Métrica Principal**: Balanced Accuracy (apropiada para clases desbalanceadas)\n",
    "- **Métricas Secundarias**: Precision, Recall, F1-Score, AUC-ROC\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Resultados\n",
    "\n",
    "### 6.1 Rendimiento del Modelo\n",
    "\n",
    "| Métrica | Threshold 0.5 | Threshold Óptimo | Mejora |\n",
    "|---------|---------------|------------------|--------|\n",
    "| **Balanced Accuracy** | 0.XXXX | 0.XXXX | +0.XXXX |\n",
    "| Accuracy | 0.XXXX | 0.XXXX | +0.XXXX |\n",
    "| Precision (Yes) | 0.XXXX | 0.XXXX | +0.XXXX |\n",
    "| Recall (Yes) | 0.XXXX | 0.XXXX | +0.XXXX |\n",
    "| F1-Score (Yes) | 0.XXXX | 0.XXXX | +0.XXXX |\n",
    "| AUC-ROC | 0.XXXX | 0.XXXX | - |\n",
    "\n",
    "### 6.2 Matriz de Confusión\n",
    "```\n",
    "                Predicho\n",
    "Real         No    Yes\n",
    "No          TN     FP\n",
    "Yes         FN     TP\n",
    "```\n",
    "\n",
    "### 6.3 Análisis de Resultados\n",
    "\n",
    "**Fortalezas del Modelo**:\n",
    "- Balanced Accuracy superior a 0.XX indica buen rendimiento en ambas clases\n",
    "- Robustez demostrada mediante validación cruzada\n",
    "\n",
    "**Limitaciones**:\n",
    "- [Analizar trade-offs específicos entre precision y recall]\n",
    "- [Comentar sobre posibles sesgos o limitaciones]\n",
    "\n",
    "---\n",
    "\n",
    "## 7. Importancia de Features\n",
    "\n",
    "[Incluir análisis de las variables más importantes según el modelo final]\n",
    "\n",
    "Las variables más predictivas identificadas fueron:\n",
    "1. **Total Active Years**\n",
    "2. **Years with Current Manager**\n",
    "3. **Features Engineered**: `Manager_Stability`\n",
    "\n",
    "---\n",
    "\n",
    "## 8. Conclusiones\n",
    "\n",
    "### 8.1 Logros Principales\n",
    "1. **Feature Engineering**: Las 13 variables derivadas mejoraron significativamente el rendimiento\n",
    "2. **Balanceamiento Inteligente**: BorderlineSMOTE superó a SMOTE estándar\n",
    "3. **Optimización de Threshold**: Mejora adicional en balanced accuracy\n",
    "4. **Pipeline Robusto**: Manejo completo de preprocesamiento y validación\n",
    "\n",
    "### 8.2 Trabajo Futuro\n",
    "- **Interpretabilidad**: Implementar SHAP/LIME para explicabilidad\n",
    "- **Stacking de Modelos**: Combinar múltiples algoritmos/Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f7de99",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
