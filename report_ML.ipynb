{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2308f556",
   "metadata": {},
   "source": [
    "# Report Práctica Predicción Abandono"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21005b5a",
   "metadata": {},
   "source": [
    "___________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34363eb5",
   "metadata": {},
   "source": [
    "En las siguientes celdas adjunto el código que he usado para entrenar el módelo (Gradient Boosting) con el que he obtenido los mejores resultados en balanced accuracy. No obstante, ha habido muchas más fases en este proyecto en las que el código no resultaba así. \n",
    "\n",
    "Debajo de las conclusiones y resultados podrá encontrar las diferentes pruebas tanto de modelos como parámetros o limpieza/preprocesado que se han hecho"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272267d0",
   "metadata": {},
   "source": [
    "___________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71a7e2f",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "996d720b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (balanced_accuracy_score, classification_report,\n",
    "                              confusion_matrix, roc_auc_score, accuracy_score,\n",
    "                              precision_score, recall_score, f1_score)\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import ExtraTreesClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.experimental import enable_halving_search_cv  # noqa: F401\n",
    "from sklearn.model_selection import HalvingRandomSearchCV\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "random.seed(100473223)\n",
    "np.random.seed(100473223)\n",
    "from sklearn.pipeline import Pipeline as SkPipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7203e313",
   "metadata": {},
   "source": [
    "### 1. Carga y Exploración de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d55ff778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dimensiones del dataset: (3528, 27)\n",
      "\n",
      "Distribución de la clase objetivo (Attrition):\n",
      "Attrition\n",
      "No     2956\n",
      "Yes     572\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Porcentaje de Attrition:\n",
      "Attrition\n",
      "No     83.786848\n",
      "Yes    16.213152\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "⚠ Ratio de desbalanceo: 5.17:1\n",
      "Clase minoritaria (Yes): 16.2%\n",
      "→ Se usará SMOTE en el pipeline de entrenamiento y CV.\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('train.csv')\n",
    "\n",
    "print(f\"\\nDimensiones del dataset: {data.shape}\")\n",
    "print(f\"\\nDistribución de la clase objetivo (Attrition):\")\n",
    "print(data['Attrition'].value_counts())\n",
    "attrition_dist = data['Attrition'].value_counts(normalize=True) * 100\n",
    "print(f\"\\nPorcentaje de Attrition:\\n{attrition_dist}\")\n",
    "\n",
    "# Ratio de desbalanceo (solo informativo)\n",
    "class_counts = data['Attrition'].value_counts()\n",
    "imbalance_ratio = class_counts['No'] / class_counts['Yes']\n",
    "print(f\"\\n⚠ Ratio de desbalanceo: {imbalance_ratio:.2f}:1\")\n",
    "print(f\"Clase minoritaria (Yes): {attrition_dist['Yes']:.1f}%\")\n",
    "print(\"→ Se usará SMOTE en el pipeline de entrenamiento y CV.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233cdf0e",
   "metadata": {},
   "source": [
    "### 2. División en Entrenamiento y Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "465403be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Conjunto de entrenamiento: 2822 instancias\n",
      "Conjunto de test: 706 instancias\n",
      "\n",
      "Distribución en entrenamiento:\n",
      "Attrition\n",
      "0    2364\n",
      "1     458\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Distribución en test:\n",
      "Attrition\n",
      "0    592\n",
      "1    114\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X = data.drop(['Attrition', 'ID'], axis=1)\n",
    "y = data['Attrition'].map({'No': 0, 'Yes': 1})\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, shuffle=True, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"\\nConjunto de entrenamiento: {X_train.shape[0]} instancias\")\n",
    "print(f\"Conjunto de test: {X_test.shape[0]} instancias\")\n",
    "print(f\"\\nDistribución en entrenamiento:\\n{y_train.value_counts()}\")\n",
    "print(f\"\\nDistribución en test:\\n{y_test.value_counts()}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa565ec2",
   "metadata": {},
   "source": [
    "### 3. Preprocesado de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c39f494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Columnas numéricas: 15\n",
      "Columnas ordinales: 3\n",
      "Columnas categóricas: 7\n",
      "\n",
      "==================================================\n",
      "ANÁLISIS DE VALORES FALTANTES\n",
      "==================================================\n",
      "                       Columna  Valores_Faltantes  Porcentaje\n",
      "        Amount of Stock Option               1213   42.983700\n",
      "       Miles from Home to Work                572   20.269313\n",
      "                Marital Status                419   14.847626\n",
      "Work Life Balance Satisfaction                168    5.953225\n",
      "              Job Satisfaction                154    5.457123\n",
      "      Environment Satisfaction                139    4.925585\n",
      "     Number of Other Companies                 11    0.389794\n",
      "            Total Active Years                  4    0.141743\n",
      "\n",
      "Total de columnas con valores faltantes: 8\n",
      "\n",
      "⚠ Eliminando columnas con >30% de valores faltantes: ['Amount of Stock Option']\n",
      "✓ Columnas eliminadas. Nuevas dimensiones: (2822, 24)\n"
     ]
    }
   ],
   "source": [
    "numerical_cols = [\n",
    "    'Age', 'Miles from Home to Work', 'Yearly Income', 'Absences per Year',\n",
    "    'Performance Rating', 'Job Satisfaction', 'Environment Satisfaction',\n",
    "    'Work Life Balance Satisfaction', 'Last Salary Increase (%)',\n",
    "    'Number of Training Sessions Last Year', 'Number of Other Companies',\n",
    "    'Total Active Years', 'Years at Current Company',\n",
    "    'Years Since Last Promotion', 'Years with Current Manager'\n",
    "]\n",
    "\n",
    "ordinal_cols = {\n",
    "    'Education Level': [['High School', 'College', 'Bachelor', 'Master', 'Doctor']],\n",
    "    'Job Level': [['Entry Level', 'Mid Level', 'Senior Level', 'Director', 'Executive']],\n",
    "    'Job Involvement': [['Low', 'Medium', 'High', 'Very High']]\n",
    "}\n",
    "\n",
    "categorical_cols = [\n",
    "    'Gender', 'Marital Status', 'Education Field', 'Department Name',\n",
    "    'Job Role Name', 'Business Travel Frequency', 'Amount of Stock Option'\n",
    "]\n",
    "\n",
    "print(f\"\\nColumnas numéricas: {len(numerical_cols)}\")\n",
    "print(f\"Columnas ordinales: {len(ordinal_cols)}\")\n",
    "print(f\"Columnas categóricas: {len(categorical_cols)}\")\n",
    "\n",
    "\n",
    "# Análisis de valores faltantes\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ANÁLISIS DE VALORES FALTANTES\")\n",
    "print(\"=\"*50)\n",
    "missing_values = X_train.isnull().sum()\n",
    "missing_percent = (missing_values / len(X_train)) * 100\n",
    "missing_df = pd.DataFrame({\n",
    "    'Columna': missing_values.index,\n",
    "    'Valores_Faltantes': missing_values.values,\n",
    "    'Porcentaje': missing_percent.values\n",
    "})\n",
    "missing_df = missing_df[missing_df['Valores_Faltantes'] > 0].sort_values('Valores_Faltantes', ascending=False)\n",
    "if len(missing_df) > 0:\n",
    "    print(missing_df.to_string(index=False))\n",
    "else:\n",
    "    print(\"✓ No hay valores faltantes en el dataset\")\n",
    "print(f\"\\nTotal de columnas con valores faltantes: {len(missing_df)}\")\n",
    "    \n",
    "# Eliminar columnas con >30% de valores faltantes\n",
    "cols_to_drop = missing_df[missing_df['Porcentaje'] > 30]['Columna'].tolist()\n",
    "if cols_to_drop:\n",
    "    print(f\"\\n⚠ Eliminando columnas con >30% de valores faltantes: {cols_to_drop}\")\n",
    "    X_train = X_train.drop(columns=cols_to_drop)\n",
    "    X_test = X_test.drop(columns=cols_to_drop)\n",
    "    \n",
    "    # Actualizar listas de columnas\n",
    "    numerical_cols = [col for col in numerical_cols if col not in cols_to_drop]\n",
    "    categorical_cols = [col for col in categorical_cols if col not in cols_to_drop]\n",
    "    ordinal_cols = {k: v for k, v in ordinal_cols.items() if k not in cols_to_drop}\n",
    "    \n",
    "    print(f\"✓ Columnas eliminadas. Nuevas dimensiones: {X_train.shape}\")\n",
    "else:\n",
    "    print(\"✓ No hay valores faltantes en el dataset\")\n",
    "# === PREPROCESADO ===\n",
    "\n",
    "# 1) Transformadores por tipo de columna\n",
    "num_transformer = SkPipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Un pipeline ordinal por cada columna ordinal (imputar + codificar)\n",
    "ord_transformers = []\n",
    "for col, categories in ordinal_cols.items():\n",
    "    ord_transformers.append((\n",
    "        f'ord_{col}',\n",
    "        SkPipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "            ('encoder', OrdinalEncoder(\n",
    "                categories=categories,\n",
    "                handle_unknown='use_encoded_value',\n",
    "                unknown_value=-1\n",
    "            ))        \n",
    "        ]),\n",
    "        [col]\n",
    "    ))\n",
    "\n",
    "cat_transformer = SkPipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(sparse_output=False, handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# 2) Un único ColumnTransformer como preprocesador\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', num_transformer, numerical_cols),\n",
    "        *ord_transformers,\n",
    "        ('cat', cat_transformer, categorical_cols)\n",
    "    ],\n",
    "    remainder='drop',\n",
    "    verbose_feature_names_out=False\n",
    ")\n",
    "\n",
    "# 3) Pipeline FINAL con SMOTE (Sin nested Pipeline en pasos intermedios)\n",
    "ml_pipe_smote = ImbPipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('classifier', LogisticRegression())  # placeholder; lo sobreescribe el Grid\n",
    "])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9561706a",
   "metadata": {},
   "source": [
    "### Modelos a probar: (Las pruebas descartadas están incluidas debajo de los resultados oficiales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bb5ddfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid= [\n",
    "    # Gradient Boosting - Excelente para balanced accuracy\n",
    "    {\n",
    "        'classifier': [GradientBoostingClassifier(random_state=42)],\n",
    "        'classifier__n_estimators': [200, 400, 600],\n",
    "        'classifier__learning_rate': [0.05, 0.1, 0.15],\n",
    "        'classifier__max_depth': [3, 4, 5],\n",
    "        'classifier__subsample': [0.8, 0.9],\n",
    "        'classifier__min_samples_leaf': [3, 5, 7]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241e3d0f",
   "metadata": {},
   "source": [
    "### Inicializamos la búsqueda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f25b0afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iniciando búsqueda CON SMOTE integrado (CV estratificada)...\n",
      "Fitting 5 folds for each of 162 candidates, totalling 810 fits\n",
      "✓ Búsqueda CON SMOTE completada!\n",
      "\n",
      "Mejor modelo CON SMOTE:\n",
      "  Clasificador: GradientBoostingClassifier\n",
      "  Balanced Accuracy (CV): 0.9067\n"
     ]
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "search_smote = GridSearchCV(\n",
    "    estimator=ml_pipe_smote,   # ImbPipeline\n",
    "    param_grid=grid,\n",
    "    scoring='balanced_accuracy',\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    error_score='raise',\n",
    "    verbose = 1,\n",
    ")\n",
    "\n",
    "\n",
    "print(\"\\nIniciando búsqueda CON SMOTE integrado (CV estratificada)...\")\n",
    "search_smote.fit(X_train, y_train)\n",
    "print(\"✓ Búsqueda CON SMOTE completada!\")\n",
    "\n",
    "print(f\"\\nMejor modelo CON SMOTE:\")\n",
    "print(f\"  Clasificador: {search_smote.best_estimator_['classifier'].__class__.__name__}\")\n",
    "print(f\"  Balanced Accuracy (CV): {search_smote.best_score_:.4f}\")\n",
    "\n",
    "best_model = search_smote.best_estimator_\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4afccfea",
   "metadata": {},
   "source": [
    "### 5. Evaluación en test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "003e27d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Métricas en test (CON SMOTE):\n",
      "          Métrica  Con SMOTE\n",
      "Balanced Accuracy   0.959845\n",
      "         Accuracy   0.980170\n",
      "  Precision (Yes)   0.946429\n",
      "     Recall (Yes)   0.929825\n",
      "   F1-Score (Yes)   0.938053\n",
      "          AUC-ROC   0.976485\n",
      "\n",
      "Matriz de Confusión (CON SMOTE):\n",
      "[[586   6]\n",
      " [  8 106]]\n",
      "  TP=106, FP=6, FN=8, TN=586\n",
      "\n",
      "REPORTE DE CLASIFICACIÓN (CON SMOTE):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "No Attrition       0.99      0.99      0.99       592\n",
      "   Attrition       0.95      0.93      0.94       114\n",
      "\n",
      "    accuracy                           0.98       706\n",
      "   macro avg       0.97      0.96      0.96       706\n",
      "weighted avg       0.98      0.98      0.98       706\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = best_model.predict(X_test)\n",
    "y_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "ba = balanced_accuracy_score(y_test, y_pred)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred)\n",
    "rec = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "auc = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Métrica': ['Balanced Accuracy', 'Accuracy', 'Precision (Yes)', 'Recall (Yes)', 'F1-Score (Yes)', 'AUC-ROC'],\n",
    "    'Con SMOTE': [ba, acc, prec, rec, f1, auc]\n",
    "})\n",
    "print(\"\\nMétricas en test (CON SMOTE):\")\n",
    "print(metrics_df.to_string(index=False))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "print(\"\\nMatriz de Confusión (CON SMOTE):\")\n",
    "print(cm)\n",
    "print(f\"  TP={tp}, FP={fp}, FN={fn}, TN={tn}\")\n",
    "\n",
    "print(\"\\nREPORTE DE CLASIFICACIÓN (CON SMOTE):\")\n",
    "print(classification_report(y_test, y_pred, target_names=['No Attrition', 'Attrition']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28cfad2c",
   "metadata": {},
   "source": [
    "### 6. Guardar Modelo y Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33a388ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Modelo guardado: best_model_final.pkl (CON SMOTE)\n",
      "✓ Métricas guardadas: metrics_smote.csv\n",
      "\n",
      "================================================================================\n",
      "PROCESO COMPLETADO (SOLO SMOTE)\n",
      "================================================================================\n",
      "\n",
      "Archivos generados:\n",
      "  1. best_model_final.pkl - Modelo entrenado (CON SMOTE)\n",
      "  2. metrics_smote.csv    - Métricas de test\n",
      "\n",
      "Balanced Accuracy en test (SMOTE): 0.9598\n",
      "Model Parameters: \n",
      "{'classifier': GradientBoostingClassifier(random_state=42), 'classifier__learning_rate': 0.15, 'classifier__max_depth': 5, 'classifier__min_samples_leaf': 7, 'classifier__n_estimators': 600, 'classifier__subsample': 0.9}\n"
     ]
    }
   ],
   "source": [
    "with open('best_model_final.pkl', 'wb') as f:\n",
    "    pkl.dump(best_model, f)\n",
    "print(\"✓ Modelo guardado: best_model_final.pkl (CON SMOTE)\")\n",
    "\n",
    "metrics_df.to_csv('metrics_smote.csv', index=False)\n",
    "print(\"✓ Métricas guardadas: metrics_smote.csv\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PROCESO COMPLETADO (SOLO SMOTE)\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nArchivos generados:\")\n",
    "print(\"  1. best_model_final.pkl - Modelo entrenado (CON SMOTE)\")\n",
    "print(\"  2. metrics_smote.csv    - Métricas de test\")\n",
    "print(f\"\\nBalanced Accuracy en test (SMOTE): {ba:.4f}\")\n",
    "print(\"Model Parameters: \")\n",
    "print(search_smote.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c6936b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Fallo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb713ea5",
   "metadata": {},
   "source": [
    "## Parte Adicional del Proyecto: Intentos Fallidos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98be91fd",
   "metadata": {},
   "source": [
    "### Pruebas de Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5cf0a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid= [\n",
    "    # 1) Logistic Regression (l1/l2, con y sin class_weight, distintos solvers)\n",
    "{\n",
    "    'classifier': [LogisticRegression(random_state=42, max_iter=2000)],\n",
    "    'classifier__penalty': ['l2', 'l1'],\n",
    "    'classifier__solver': ['liblinear', 'saga'],   # l1 soportado por liblinear/saga\n",
    "    'classifier__C': [0.01, 0.1, 1, 3, 10],\n",
    "    'classifier__class_weight': [None, 'balanced']\n",
    "},\n",
    "   ## 2) Árbol de decisión (más profundo, min_samples_* y max_features)\n",
    "{\n",
    "    'classifier': [DecisionTreeClassifier(random_state=42)],\n",
    "    'classifier__criterion': ['gini', 'entropy', 'log_loss'],\n",
    "    'classifier__max_depth': [None, 5, 10, 20, 30],\n",
    "    'classifier__min_samples_split': [2, 5, 10, 20],\n",
    "    'classifier__min_samples_leaf': [1, 2, 5, 10],\n",
    "    'classifier__max_features': [None, 'sqrt', 'log2'],\n",
    "    'classifier__class_weight': [None, 'balanced']\n",
    "},\n",
    "   ## 3) KNN (más vecinos, distancia y leaf_size)\n",
    "{\n",
    "    'classifier': [KNeighborsClassifier()],\n",
    "    'classifier__n_neighbors': [3, 5, 7, 9, 11, 15],\n",
    "    'classifier__weights': ['uniform', 'distance'],\n",
    "    'classifier__p': [1, 2],                # manhattan / euclid\n",
    "    'classifier__leaf_size': [15, 30, 45]\n",
    "},\n",
    "  # Random Forest optimizado para balanced accuracy\n",
    "  {\n",
    "      'classifier': [RandomForestClassifier(random_state=42)],\n",
    "      'classifier__n_estimators': [300, 500, 700],\n",
    "      'classifier__max_depth': [15, 20, 25],\n",
    "      'classifier__min_samples_split': [5, 8],\n",
    "      'classifier__min_samples_leaf': [2, 3],\n",
    "      'classifier__max_features': ['sqrt', 'log2'],\n",
    "      'classifier__class_weight': ['balanced']\n",
    "  },\n",
    "   ## 5) Random Forest (más n_estimators, max_features, bootstrap)\n",
    "{\n",
    "    'classifier': [RandomForestClassifier(random_state=42)],\n",
    "    'classifier__n_estimators': [100, 300, 600],\n",
    "    'classifier__criterion': ['gini', 'entropy'],\n",
    "    'classifier__max_depth': [None, 10, 20, 40],\n",
    "    'classifier__min_samples_split': [2, 5, 10],\n",
    "    'classifier__min_samples_leaf': [1, 2, 4],\n",
    "    'classifier__max_features': ['sqrt', 'log2', None],\n",
    "    'classifier__bootstrap': [True, False],\n",
    "    'classifier__class_weight': [None, 'balanced']\n",
    "},\n",
    "   ## 6) Gradient Boosting\n",
    "{\n",
    "    'classifier': [GradientBoostingClassifier(random_state=42)],\n",
    "    'classifier__n_estimators': [100, 200, 400],\n",
    "    'classifier__learning_rate': [0.02, 0.05, 0.1, 0.2],\n",
    "    'classifier__max_depth': [2, 3, 5],\n",
    "    'classifier__min_samples_leaf': [1, 2, 5],\n",
    "    'classifier__subsample': [0.6, 0.8, 1.0]\n",
    "},\n",
    "  ## 7) Extra Trees\n",
    "{\n",
    "    'classifier': [ExtraTreesClassifier(random_state=42)],\n",
    "    'classifier__n_estimators': [200, 500, 800],\n",
    "    'classifier__criterion': ['gini', 'entropy', 'log_loss'],\n",
    "    'classifier__max_depth': [None, 10, 20, 40],\n",
    "    'classifier__min_samples_split': [2, 5, 10],\n",
    "    'classifier__min_samples_leaf': [1, 2, 4],\n",
    "    'classifier__max_features': ['sqrt', 'log2', None],\n",
    "    'classifier__bootstrap': [False],           # ExtraTrees suele ir sin bootstrap\n",
    "    'classifier__class_weight': [None, 'balanced']\n",
    "},\n",
    "  ## 8) AdaBoost\n",
    "{\n",
    "   'classifier': [AdaBoostClassifier(\n",
    "       random_state=42,\n",
    "       estimator=DecisionTreeClassifier(random_state=42)\n",
    "   )],\n",
    "   'classifier__algorithm': ['SAMME'],\n",
    "   'classifier__n_estimators': [100, 300, 600],\n",
    "   'classifier__learning_rate': [0.02, 0.05, 0.1, 0.2, 0.5],\n",
    "   'classifier__estimator__max_depth': [1, 2, 3],\n",
    "   'classifier__estimator__min_samples_leaf': [1, 2, 5]\n",
    "},\n",
    "  # Gradient Boosting\n",
    "  {\n",
    "      'classifier': [GradientBoostingClassifier(random_state=42)],\n",
    "      'classifier__n_estimators': [200, 400, 600],\n",
    "      'classifier__learning_rate': [0.05, 0.1, 0.15],\n",
    "      'classifier__max_depth': [3, 4, 5],\n",
    "      'classifier__subsample': [0.8, 0.9],\n",
    "      'classifier__min_samples_leaf': [3, 5, 7]\n",
    "  },\n",
    "  # Extra Trees\n",
    "  {\n",
    "      'classifier': [ExtraTreesClassifier(random_state=42)],\n",
    "      'classifier__n_estimators': [400, 600],\n",
    "      'classifier__max_depth': [20, 30],\n",
    "      'classifier__min_samples_split': [5, 8],\n",
    "      'classifier__min_samples_leaf': [2, 4],\n",
    "      'classifier__max_features': ['sqrt'],\n",
    "      'classifier__class_weight': ['balanced']\n",
    "  },\n",
    "  # Random Forest\n",
    "  {\n",
    "      'classifier': [RandomForestClassifier(random_state=42)],\n",
    "      'classifier__n_estimators': [300, 500],\n",
    "      'classifier__class_weight': ['balanced']\n",
    "  }\n",
    "]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b49bb2",
   "metadata": {},
   "source": [
    "## Parte Adicional del Proyecto: Posibles Mejoras"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
