{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2308f556",
   "metadata": {},
   "source": [
    "# Report Práctica Predicción Abandono"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21005b5a",
   "metadata": {},
   "source": [
    "___________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34363eb5",
   "metadata": {},
   "source": [
    "En las siguientes celdas adjunto el código que he usado para entrenar el módelo (Gradient Boosting) con el que he obtenido los mejores resultados en balanced accuracy. No obstante, ha habido muchas más fases en este proyecto en las que el código no resultaba así. \n",
    "\n",
    "Debajo de las conclusiones y resultados podrá encontrar las diferentes pruebas tanto de modelos como parámetros o limpieza/preprocesado que se han hecho"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272267d0",
   "metadata": {},
   "source": [
    "___________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71a7e2f",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "996d720b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "# Preprocesado\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from imblearn.over_sampling import SMOTE, BorderlineSMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "\n",
    "# Prueba de Modelos\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier, AdaBoostClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "# Evaluacion\n",
    "from sklearn.metrics import (balanced_accuracy_score, classification_report,\n",
    "                              confusion_matrix, roc_auc_score, accuracy_score,\n",
    "                              precision_score, recall_score, f1_score)\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "\n",
    "# Fijamos Semilla\n",
    "random.seed(100473223)\n",
    "np.random.seed(100473223)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a61ed0e",
   "metadata": {},
   "source": [
    "### Clase de Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "42427e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureEngineer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Crea features derivadas para capturar patrones no lineales\"\"\"\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        \n",
    "        # Evitar división por cero\n",
    "        def safe_divide(a, b):\n",
    "            return np.where(b != 0, a / b, 0)\n",
    "        \n",
    "        # Estabilidad laboral\n",
    "        X['Years_per_Company_Ratio'] = safe_divide(\n",
    "            X['Total Active Years'], \n",
    "            X['Number of Other Companies'] + 1\n",
    "        )\n",
    "        \n",
    "        # Retraso en promoción\n",
    "        X['Promotion_Lag'] = X['Years at Current Company'] - X['Years Since Last Promotion']\n",
    "        \n",
    "        # Ingreso por año de experiencia\n",
    "        X['Income_per_Year'] = safe_divide(\n",
    "            X['Yearly Income'], \n",
    "            X['Total Active Years'] + 1\n",
    "        )\n",
    "        \n",
    "        # Estabilidad con manager actual\n",
    "        X['Manager_Stability'] = safe_divide(\n",
    "            X['Years with Current Manager'], \n",
    "            X['Years at Current Company'] + 1\n",
    "        )\n",
    "        \n",
    "        # Satisfacción general (promedio de satisfacciones)\n",
    "        satisfaction_cols = ['Job Satisfaction', 'Environment Satisfaction', \n",
    "                            'Work Life Balance Satisfaction']\n",
    "        \n",
    "        # Manejar valores faltantes temporalmente para el cálculo\n",
    "        X['Overall_Satisfaction'] = X[satisfaction_cols].mean(axis=1, skipna=True)\n",
    "        \n",
    "        # Baja satisfacción general\n",
    "        X['Low_Satisfaction'] = (X['Overall_Satisfaction'] < 3).astype(int)\n",
    "        \n",
    "        # Empleado recién contratado\n",
    "        X['Recent_Hire'] = (X['Years at Current Company'] < 2).astype(int)\n",
    "        \n",
    "        # Promoción atrasada\n",
    "        X['Overdue_Promotion'] = (X['Years Since Last Promotion'] > 3).astype(int)\n",
    "        \n",
    "        # Commute largo (si la columna existe)\n",
    "        if 'Miles from Home to Work' in X.columns:\n",
    "            X['Long_Commute'] = (X['Miles from Home to Work'] > 20).astype(int)\n",
    "        \n",
    "        # Edad vs. Nivel de trabajo (senior joven o junior viejo = señal)\n",
    "        X['Age_x_JobLevel'] = X['Age'] * pd.factorize(X.get('Job Level', pd.Series([0]*len(X))))[0]\n",
    "        \n",
    "        # Satisfacción baja + salario bajo = alto riesgo\n",
    "        X['LowSat_LowIncome'] = (\n",
    "            (X['Overall_Satisfaction'] < 3) & \n",
    "            (X['Yearly Income'] < X['Yearly Income'].median())\n",
    "        ).astype(int)\n",
    "        \n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7203e313",
   "metadata": {},
   "source": [
    "### 1. Carga y Exploración de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d55ff778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dimensiones del dataset: (3528, 27)\n",
      "\n",
      "Distribución de la clase objetivo (Attrition):\n",
      "Attrition\n",
      "No     2956\n",
      "Yes     572\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Porcentaje de Attrition:\n",
      "Attrition\n",
      "No     83.786848\n",
      "Yes    16.213152\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "⚠ Ratio de desbalanceo: 5.17:1\n",
      "Clase minoritaria (Yes): 16.2%\n",
      "→ Se usará SMOTE en el pipeline de entrenamiento y CV.\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('train.csv')\n",
    "\n",
    "print(f\"\\nDimensiones del dataset: {data.shape}\")\n",
    "print(f\"\\nDistribución de la clase objetivo (Attrition):\")\n",
    "print(data['Attrition'].value_counts())\n",
    "attrition_dist = data['Attrition'].value_counts(normalize=True) * 100\n",
    "print(f\"\\nPorcentaje de Attrition:\\n{attrition_dist}\")\n",
    "\n",
    "# Ratio de desbalanceo (solo informativo)\n",
    "class_counts = data['Attrition'].value_counts()\n",
    "imbalance_ratio = class_counts['No'] / class_counts['Yes']\n",
    "print(f\"\\n⚠ Ratio de desbalanceo: {imbalance_ratio:.2f}:1\")\n",
    "print(f\"Clase minoritaria (Yes): {attrition_dist['Yes']:.1f}%\")\n",
    "print(\"→ Se usará SMOTE en el pipeline de entrenamiento y CV.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233cdf0e",
   "metadata": {},
   "source": [
    "### 2. División en Entrenamiento y Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "465403be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Conjunto de entrenamiento: 2822 instancias\n",
      "Conjunto de test: 706 instancias\n",
      "\n",
      "Distribución en entrenamiento:\n",
      "Attrition\n",
      "0    2364\n",
      "1     458\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Distribución en test:\n",
      "Attrition\n",
      "0    592\n",
      "1    114\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X = data.drop(['Attrition', 'ID'], axis=1)\n",
    "y = data['Attrition'].map({'No': 0, 'Yes': 1})\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, shuffle=True, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"\\nConjunto de entrenamiento: {X_train.shape[0]} instancias\")\n",
    "print(f\"Conjunto de test: {X_test.shape[0]} instancias\")\n",
    "print(f\"\\nDistribución en entrenamiento:\\n{y_train.value_counts()}\")\n",
    "print(f\"\\nDistribución en test:\\n{y_test.value_counts()}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa565ec2",
   "metadata": {},
   "source": [
    "### 3. Preprocesado de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4c39f494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Columnas numéricas: 15\n",
      "Columnas ordinales: 3\n",
      "Columnas categóricas: 7\n",
      "\n",
      "==================================================\n",
      "ANÁLISIS DE VALORES FALTANTES\n",
      "==================================================\n",
      "                       Columna  Valores_Faltantes  Porcentaje\n",
      "        Amount of Stock Option               1213   42.983700\n",
      "       Miles from Home to Work                572   20.269313\n",
      "                Marital Status                419   14.847626\n",
      "Work Life Balance Satisfaction                168    5.953225\n",
      "              Job Satisfaction                154    5.457123\n",
      "      Environment Satisfaction                139    4.925585\n",
      "     Number of Other Companies                 11    0.389794\n",
      "            Total Active Years                  4    0.141743\n",
      "\n",
      "Total de columnas con valores faltantes: 8\n",
      "\n",
      "⚠ Eliminando columnas con >30% de valores faltantes: ['Amount of Stock Option']\n",
      "✓ Columnas eliminadas. Nuevas dimensiones: (2822, 24)\n"
     ]
    }
   ],
   "source": [
    "numerical_cols = [\n",
    "    'Age', 'Miles from Home to Work', 'Yearly Income', 'Absences per Year',\n",
    "    'Performance Rating', 'Job Satisfaction', 'Environment Satisfaction',\n",
    "    'Work Life Balance Satisfaction', 'Last Salary Increase (%)',\n",
    "    'Number of Training Sessions Last Year', 'Number of Other Companies',\n",
    "    'Total Active Years', 'Years at Current Company',\n",
    "    'Years Since Last Promotion', 'Years with Current Manager'\n",
    "]\n",
    "\n",
    "ordinal_cols = {\n",
    "    'Education Level': [['High School', 'College', 'Bachelor', 'Master', 'Doctor']],\n",
    "    'Job Level': [['Entry Level', 'Mid Level', 'Senior Level', 'Director', 'Executive']],\n",
    "    'Job Involvement': [['Low', 'Medium', 'High', 'Very High']]\n",
    "}\n",
    "\n",
    "categorical_cols = [\n",
    "    'Gender', 'Marital Status', 'Education Field', 'Department Name',\n",
    "    'Job Role Name', 'Business Travel Frequency', 'Amount of Stock Option'\n",
    "]\n",
    "\n",
    "print(f\"\\nColumnas numéricas: {len(numerical_cols)}\")\n",
    "print(f\"Columnas ordinales: {len(ordinal_cols)}\")\n",
    "print(f\"Columnas categóricas: {len(categorical_cols)}\")\n",
    "\n",
    "\n",
    "# Análisis de valores faltantes\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ANÁLISIS DE VALORES FALTANTES\")\n",
    "print(\"=\"*50)\n",
    "missing_values = X_train.isnull().sum()\n",
    "missing_percent = (missing_values / len(X_train)) * 100\n",
    "missing_df = pd.DataFrame({\n",
    "    'Columna': missing_values.index,\n",
    "    'Valores_Faltantes': missing_values.values,\n",
    "    'Porcentaje': missing_percent.values\n",
    "})\n",
    "missing_df = missing_df[missing_df['Valores_Faltantes'] > 0].sort_values('Valores_Faltantes', ascending=False)\n",
    "if len(missing_df) > 0:\n",
    "    print(missing_df.to_string(index=False))\n",
    "else:\n",
    "    print(\"✓ No hay valores faltantes en el dataset\")\n",
    "print(f\"\\nTotal de columnas con valores faltantes: {len(missing_df)}\")\n",
    "    \n",
    "# Eliminar columnas con >30% de valores faltantes\n",
    "cols_to_drop = missing_df[missing_df['Porcentaje'] > 30]['Columna'].tolist()\n",
    "if cols_to_drop:\n",
    "    print(f\"\\n⚠ Eliminando columnas con >30% de valores faltantes: {cols_to_drop}\")\n",
    "    X_train = X_train.drop(columns=cols_to_drop)\n",
    "    X_test = X_test.drop(columns=cols_to_drop)\n",
    "    \n",
    "    # Actualizar listas de columnas\n",
    "    numerical_cols = [col for col in numerical_cols if col not in cols_to_drop]\n",
    "    categorical_cols = [col for col in categorical_cols if col not in cols_to_drop]\n",
    "    ordinal_cols = {k: v for k, v in ordinal_cols.items() if k not in cols_to_drop}\n",
    "    \n",
    "    print(f\"✓ Columnas eliminadas. Nuevas dimensiones: {X_train.shape}\")\n",
    "else:\n",
    "    print(\"✓ No hay valores faltantes en el dataset\")\n",
    "# === PREPROCESADO ===\n",
    "\n",
    "# 1) Transformadores por tipo de columna\n",
    "num_transformer = ImbPipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Un pipeline ordinal por cada columna ordinal (imputar + codificar)\n",
    "ord_transformers = []\n",
    "for col, categories in ordinal_cols.items():\n",
    "    ord_transformers.append((\n",
    "        f'ord_{col}',\n",
    "        ImbPipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "            ('encoder', OrdinalEncoder(\n",
    "                categories=categories,\n",
    "                handle_unknown='use_encoded_value',\n",
    "                unknown_value=-1\n",
    "            ))        \n",
    "        ]),\n",
    "        [col]\n",
    "    ))\n",
    "\n",
    "cat_transformer = ImbPipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(sparse_output=False, handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# 2) Un único ColumnTransformer como preprocesador\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', num_transformer, numerical_cols),\n",
    "        *ord_transformers,\n",
    "        ('cat', cat_transformer, categorical_cols)\n",
    "    ],\n",
    "    remainder='drop',\n",
    "    verbose_feature_names_out=False\n",
    ")\n",
    "\n",
    "# 3) Pipeline FINAL con SMOTE (Sin nested Pipeline en pasos intermedios)\n",
    "# MEJORA #2: Usar BorderlineSMOTE en lugar de SMOTE\n",
    "ml_pipe_improved = ImbPipeline(steps=[\n",
    "    ('feature_engineer', FeatureEngineer()),  # \"Juego de features\"\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('smote', BorderlineSMOTE(random_state=42, kind='borderline-1')),  # Tiene en cuenta los bordes\n",
    "    ('classifier', LogisticRegression())  # placeholder\n",
    "])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9561706a",
   "metadata": {},
   "source": [
    "### Modelos a probar: \n",
    "(Las pruebas descartadas están incluidas debajo de los resultados oficiales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6bb5ddfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid= [\n",
    "    # Gradient Boosting - Excelente para balanced accuracy\n",
    "    {\n",
    "        'classifier': [GradientBoostingClassifier(random_state=42)],\n",
    "        'classifier__n_estimators': [600],\n",
    "        'classifier__learning_rate': [0.15],\n",
    "        'classifier__max_depth': [5],\n",
    "        'classifier__subsample': [0.9],\n",
    "        'classifier__min_samples_leaf': [7]\n",
    "    }\n",
    "]\n",
    "# La mejor combinación será (en mi experiencia): {'classifier': GradientBoostingClassifier(random_state=42), 'classifier__learning_rate': 0.15, 'classifier__max_depth': 5, 'classifier__min_samples_leaf': 7, 'classifier__n_estimators': 600, 'classifier__subsample': 0.9}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241e3d0f",
   "metadata": {},
   "source": [
    "### Inicializamos la búsqueda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f25b0afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iniciando búsqueda CON SMOTE integrado (CV estratificada)...\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Búsqueda CON SMOTE completada!\n",
      "\n",
      "Mejor modelo CON SMOTE:\n",
      "  Clasificador: GradientBoostingClassifier\n",
      "  Balanced Accuracy (CV): 0.9021\n",
      "Threshold por defecto (0.5): 1.0000\n",
      "Threshold óptimo encontrado: 0.100\n",
      "Balanced Accuracy con threshold óptimo: 1.0000\n",
      "Mejora: +0.0000\n"
     ]
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "search_smote = GridSearchCV(\n",
    "    estimator=ml_pipe_improved,   # ImbPipeline\n",
    "    param_grid=grid,\n",
    "    scoring='balanced_accuracy',\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    error_score='raise',\n",
    "    verbose = 1,\n",
    ")\n",
    "\n",
    "\n",
    "print(\"\\nIniciando búsqueda CON SMOTE integrado (CV estratificada)...\")\n",
    "search_smote.fit(X_train, y_train)\n",
    "print(\"✓ Búsqueda CON SMOTE completada!\")\n",
    "\n",
    "print(f\"\\nMejor modelo CON SMOTE:\")\n",
    "print(f\"  Clasificador: {search_smote.best_estimator_['classifier'].__class__.__name__}\")\n",
    "print(f\"  Balanced Accuracy (CV): {search_smote.best_score_:.4f}\")\n",
    "\n",
    "best_model = search_smote.best_estimator_\n",
    "\n",
    "def find_optimal_threshold(model, X_val, y_val):\n",
    "    \"\"\"Encuentra el threshold óptimo para balanced accuracy\"\"\"\n",
    "    y_proba = model.predict_proba(X_val)[:, 1]\n",
    "    \n",
    "    thresholds = np.arange(0.1, 0.9, 0.01)\n",
    "    scores = []\n",
    "    \n",
    "    for thresh in thresholds:\n",
    "        y_pred = (y_proba >= thresh).astype(int)\n",
    "        score = balanced_accuracy_score(y_val, y_pred)\n",
    "        scores.append(score)\n",
    "    \n",
    "    optimal_idx = np.argmax(scores)\n",
    "    optimal_threshold = thresholds[optimal_idx]\n",
    "    optimal_score = scores[optimal_idx]\n",
    "    \n",
    "    print(f\"Threshold por defecto (0.5): {balanced_accuracy_score(y_val, (y_proba >= 0.5).astype(int)):.4f}\")\n",
    "    print(f\"Threshold óptimo encontrado: {optimal_threshold:.3f}\")\n",
    "    print(f\"Balanced Accuracy con threshold óptimo: {optimal_score:.4f}\")\n",
    "    print(f\"Mejora: +{(optimal_score - balanced_accuracy_score(y_val, (y_proba >= 0.5).astype(int))):.4f}\")\n",
    "    \n",
    "    return optimal_threshold\n",
    "\n",
    "# Encontrar threshold óptimo en train\n",
    "optimal_threshold = find_optimal_threshold(best_model, X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8089890",
   "metadata": {},
   "source": [
    "### Mejor Modelo:\n",
    "{'classifier': GradientBoostingClassifier(random_state=42), 'classifier__learning_rate': 0.15, 'classifier__max_depth': 5, 'classifier__min_samples_leaf': 7, 'classifier__n_estimators': 600, 'classifier__subsample': 0.9}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4afccfea",
   "metadata": {},
   "source": [
    "### 5. Evaluación en test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003e27d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 COMPARACIÓN DE RESULTADOS:\n",
      "          Métrica  Threshold 0.5  Threshold Óptimo    Mejora\n",
      "Balanced Accuracy       0.949384          0.965238  0.015855\n",
      "         Accuracy       0.974504          0.977337  0.002833\n",
      "  Precision (Yes)       0.928571          0.915254 -0.013317\n",
      "     Recall (Yes)       0.912281          0.947368  0.035088\n",
      "   F1-Score (Yes)       0.920354          0.931034  0.010681\n",
      "          AUC-ROC       0.976307          0.976307  0.000000\n",
      "\n",
      "🎉 Balanced Accuracy Final: 0.9652\n",
      "   Mejora vs threshold 0.5: +0.0159\n",
      "\n",
      "📋 Matriz de Confusión (Threshold Óptimo):\n",
      "[[582  10]\n",
      " [  6 108]]\n",
      "  TP=108, FP=10, FN=6, TN=582\n",
      "\n",
      "📄 REPORTE DE CLASIFICACIÓN (Threshold Óptimo):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "No Attrition       0.99      0.98      0.99       592\n",
      "   Attrition       0.92      0.95      0.93       114\n",
      "\n",
      "    accuracy                           0.98       706\n",
      "   macro avg       0.95      0.97      0.96       706\n",
      "weighted avg       0.98      0.98      0.98       706\n",
      "\n",
      "\n",
      "================================================================================\n",
      "6. GUARDADO DE MODELO Y RESULTADOS\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Predicciones con threshold por defecto (0.5)\n",
    "y_pred_default = best_model.predict(X_test)\n",
    "y_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Predicciones con threshold óptimo\n",
    "y_pred_optimal = (y_proba >= optimal_threshold).astype(int)\n",
    "\n",
    "# Métricas con threshold por defecto\n",
    "ba_default = balanced_accuracy_score(y_test, y_pred_default)\n",
    "acc_default = accuracy_score(y_test, y_pred_default)\n",
    "prec_default = precision_score(y_test, y_pred_default)\n",
    "rec_default = recall_score(y_test, y_pred_default)\n",
    "f1_default = f1_score(y_test, y_pred_default)\n",
    "\n",
    "# Métricas con threshold óptimo\n",
    "ba_optimal = balanced_accuracy_score(y_test, y_pred_optimal)\n",
    "acc_optimal = accuracy_score(y_test, y_pred_optimal)\n",
    "prec_optimal = precision_score(y_test, y_pred_optimal)\n",
    "rec_optimal = recall_score(y_test, y_pred_optimal)\n",
    "f1_optimal = f1_score(y_test, y_pred_optimal)\n",
    "auc = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "# Comparación de métricas\n",
    "metrics_comparison = pd.DataFrame({\n",
    "    'Métrica': ['Balanced Accuracy', 'Accuracy', 'Precision (Yes)', 'Recall (Yes)', 'F1-Score (Yes)', 'AUC-ROC'],\n",
    "    'Threshold 0.5': [ba_default, acc_default, prec_default, rec_default, f1_default, auc],\n",
    "    'Threshold Óptimo': [ba_optimal, acc_optimal, prec_optimal, rec_optimal, f1_optimal, auc],\n",
    "    'Mejora': [\n",
    "        ba_optimal - ba_default,\n",
    "        acc_optimal - acc_default,\n",
    "        prec_optimal - prec_default,\n",
    "        rec_optimal - rec_default,\n",
    "        f1_optimal - f1_default,\n",
    "        0\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\n📊 COMPARACIÓN DE RESULTADOS:\")\n",
    "print(metrics_comparison.to_string(index=False))\n",
    "\n",
    "print(f\"\\n🎉 Balanced Accuracy Final: {ba_optimal:.4f}\")\n",
    "print(f\"   Mejora vs threshold 0.5: +{(ba_optimal - ba_default):.4f}\")\n",
    "\n",
    "# Matriz de confusión con threshold óptimo\n",
    "cm = confusion_matrix(y_test, y_pred_optimal)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "print(\"\\n📋 Matriz de Confusión (Threshold Óptimo):\")\n",
    "print(cm)\n",
    "print(f\"  TP={tp}, FP={fp}, FN={fn}, TN={tn}\")\n",
    "\n",
    "print(\"\\n📄 REPORTE DE CLASIFICACIÓN (Threshold Óptimo):\")\n",
    "print(classification_report(y_test, y_pred_optimal, target_names=['No Attrition', 'Attrition']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28cfad2c",
   "metadata": {},
   "source": [
    "### 6. Guardar Modelo y Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a388ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Modelo mejorado guardado: best_model_improved.pkl\n",
      "  (incluye threshold óptimo: 0.100)\n"
     ]
    }
   ],
   "source": [
    "model_data = {\n",
    "    'model': best_model,\n",
    "    'optimal_threshold': optimal_threshold,\n",
    "    'feature_names': X_train.columns.tolist()\n",
    "}\n",
    "with open('best_model_improved.pkl', 'wb') as f:\n",
    "    pkl.dump(model_data, f)\n",
    "print(\"✓ Modelo mejorado guardado: best_model_improved.pkl\")\n",
    "print(f\"  (incluye threshold óptimo: {optimal_threshold:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb713ea5",
   "metadata": {},
   "source": [
    "## Parte Adicional del Proyecto: Intentos Fallidos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98be91fd",
   "metadata": {},
   "source": [
    "### Pruebas de Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a5cf0a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid= [\n",
    "    # 1) Logistic Regression (l1/l2, con y sin class_weight, distintos solvers)\n",
    "{\n",
    "    'classifier': [LogisticRegression(random_state=42, max_iter=2000)],\n",
    "    'classifier__penalty': ['l2', 'l1'],\n",
    "    'classifier__solver': ['liblinear', 'saga'],   # l1 soportado por liblinear/saga\n",
    "    'classifier__C': [0.1, 1, 3, 10],\n",
    "    'classifier__class_weight': ['balanced'],\n",
    "},\n",
    "   ## 2) Árbol de decisión (más profundo, min_samples_* y max_features)\n",
    "{\n",
    "    'classifier': [DecisionTreeClassifier(random_state=42)],\n",
    "    'classifier__criterion': ['gini', 'entropy', 'log_loss'],\n",
    "    'classifier__max_depth': [None, 5, 10, 20],\n",
    "    'classifier__min_samples_split': [2, 5, 10],\n",
    "    'classifier__min_samples_leaf': [1, 2, 5],\n",
    "    'classifier__class_weight': ['balanced']\n",
    "},\n",
    "   ## 3) KNN (más vecinos, distancia y leaf_size)\n",
    "{\n",
    "    'classifier': [KNeighborsClassifier()],\n",
    "    'classifier__n_neighbors': [3, 5, 7, 9, 11, 15],\n",
    "    'classifier__weights': ['uniform', 'distance'],\n",
    "    'classifier__p': [1, 2],                # manhattan / euclid\n",
    "    'classifier__leaf_size': [15, 30, 45]\n",
    "},\n",
    "  # Random Forest optimizado para balanced accuracy\n",
    "   ## 5) Random Forest (más n_estimators, max_features, bootstrap)\n",
    "{\n",
    "    'classifier': [RandomForestClassifier(random_state=42)],\n",
    "    'classifier__n_estimators': [100, 300, 500],\n",
    "    'classifier__criterion': ['gini', 'entropy'],\n",
    "    'classifier__max_depth': [None, 10, 20],\n",
    "    'classifier__min_samples_split': [2, 5, 10],\n",
    "    'classifier__min_samples_leaf': [1, 2, 4],\n",
    "    'classifier__class_weight': ['balanced']\n",
    "},\n",
    "   ## 6) Gradient Boosting\n",
    "{\n",
    "    'classifier': [GradientBoostingClassifier(random_state=42)],\n",
    "    'classifier__n_estimators': [100, 200, 400, 600],\n",
    "    'classifier__learning_rate': [0.02, 0.05, 0.1, 0.2],\n",
    "    'classifier__max_depth': [2, 3, 5],\n",
    "    'classifier__min_samples_leaf': [1, 2, 5],\n",
    "    'classifier__subsample': [0.6, 0.8, 0.9, 1.0]\n",
    "},\n",
    "  ## 7) Extra Trees\n",
    "{\n",
    "    'classifier': [ExtraTreesClassifier(random_state=42)],\n",
    "    'classifier__n_estimators': [200, 500],\n",
    "    'classifier__criterion': ['gini', 'entropy', 'log_loss'],\n",
    "    'classifier__max_depth': [None, 10, 20],\n",
    "    'classifier__min_samples_split': [2, 5, 10],\n",
    "    'classifier__min_samples_leaf': [1, 2, 4],\n",
    "    'classifier__class_weight': ['balanced']\n",
    "},\n",
    "  ## 8) AdaBoost\n",
    "{\n",
    "   'classifier': [AdaBoostClassifier(\n",
    "       random_state=42,\n",
    "       estimator=DecisionTreeClassifier(random_state=42)\n",
    "   )],\n",
    "   'classifier__algorithm': ['SAMME'],\n",
    "   'classifier__n_estimators': [100, 300],\n",
    "   'classifier__learning_rate': [0.1, 0.2, 0.5],\n",
    "   'classifier__estimator__max_depth': [1, 2, 3],\n",
    "   'classifier__estimator__min_samples_leaf': [1, 2, 5]\n",
    "},\n",
    "  # multi-layer Perceptron\n",
    "  {\n",
    "      'classifier': [MLPClassifier(random_state=42, max_iter=1000)],\n",
    "      'classifier__hidden_layer_sizes': [(50,), (100,), (50, 50)],\n",
    "      'classifier__activation': ['relu', 'tanh'],\n",
    "      'classifier__alpha': [0.001, 0.01]\n",
    "  }\n",
    "]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fa0333",
   "metadata": {},
   "source": [
    "### Plot de los resultados con varios modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "95fa47f3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ml_pipe_smote' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 16\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 7. RESUMEN COMPLETO DE LA BÚSQUEDA + PLOT\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m#    verbose = 1,\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m#)\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RandomizedSearchCV\n\u001b[1;32m     15\u001b[0m search \u001b[38;5;241m=\u001b[39m RandomizedSearchCV(\n\u001b[0;32m---> 16\u001b[0m     estimator\u001b[38;5;241m=\u001b[39m\u001b[43mml_pipe_smote\u001b[49m,\n\u001b[1;32m     17\u001b[0m     param_distributions\u001b[38;5;241m=\u001b[39mgrid,\n\u001b[1;32m     18\u001b[0m     n_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m,  \u001b[38;5;66;03m# Prueba 100 combinaciones aleatorias\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbalanced_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     20\u001b[0m     cv\u001b[38;5;241m=\u001b[39mcv,\n\u001b[1;32m     21\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     22\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     23\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m\n\u001b[1;32m     24\u001b[0m )\n\u001b[1;32m     25\u001b[0m search_smote\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m     26\u001b[0m cv_results_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(search_smote\u001b[38;5;241m.\u001b[39mcv_results_)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ml_pipe_smote' is not defined"
     ]
    }
   ],
   "source": [
    "# 7. RESUMEN COMPLETO DE LA BÚSQUEDA + PLOT\n",
    "\n",
    "#cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "#search_smote = GridSearchCV(\n",
    "#    estimator=ml_pipe_smote,   # ImbPipeline\n",
    "#    param_grid=grid,\n",
    "#    scoring='balanced_accuracy',\n",
    "#    cv=cv,\n",
    "#    n_jobs=-1,\n",
    "#    error_score='raise',\n",
    "#    verbose = 1,\n",
    "#)\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "search = RandomizedSearchCV(\n",
    "    estimator=ml_pipe_smote,\n",
    "    param_distributions=grid,\n",
    "    n_iter=100,  # Prueba 100 combinaciones aleatorias\n",
    "    scoring='balanced_accuracy',\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    random_state=42\n",
    ")\n",
    "search_smote.fit(X_train, y_train)\n",
    "cv_results_df = pd.DataFrame(search_smote.cv_results_)\n",
    "score_cols = [\n",
    "    col for col in cv_results_df.columns\n",
    "    if col.startswith('split') and col.endswith('_test_score')\n",
    "]\n",
    "summary_cols = ['params', 'mean_test_score', 'std_test_score', 'rank_test_score'] + score_cols\n",
    "cv_results_summary = cv_results_df[summary_cols].copy()\n",
    "cv_results_summary = cv_results_summary.sort_values('rank_test_score')\n",
    "\n",
    "def _format_params(params: dict) -> str:\n",
    "    return ', '.join(f\"{key}={value}\" for key, value in params.items())\n",
    "\n",
    "cv_results_summary['params'] = cv_results_summary['params'].apply(_format_params)\n",
    "cv_results_summary = cv_results_summary.rename(columns={\n",
    "    'params': 'Parámetros',\n",
    "    'mean_test_score': 'Balanced Accuracy media',\n",
    "    'std_test_score': 'Desviación estándar',\n",
    "    'rank_test_score': 'Ranking'\n",
    "})\n",
    "\n",
    "print(\"\\nResultados completos de la búsqueda (ordenados por ranking):\")\n",
    "print(cv_results_summary.to_string(index=False))\n",
    "\n",
    "cv_results_summary.to_csv('cv_results_smote.csv', index=False)\n",
    "print(\"\\n✓ Resultados de la búsqueda guardados en: cv_results_smote.csv\")\n",
    "\n",
    "if len(cv_results_summary) > 0:\n",
    "    top_n = min(10, len(cv_results_summary))\n",
    "    top_results = cv_results_summary.head(top_n)\n",
    "    plt.figure(figsize=(12, max(6, top_n * 0.5)))\n",
    "    sns.barplot(\n",
    "        data=top_results,\n",
    "        x='Balanced Accuracy media',\n",
    "        y='Parámetros',\n",
    "        palette='viridis'\n",
    "    )\n",
    "    plt.title(f'Mejores {top_n} combinaciones - Balanced Accuracy (CV)')\n",
    "    plt.xlabel('Balanced Accuracy media (CV)')\n",
    "    plt.ylabel('Parámetros')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('cv_results_smote_top.png', dpi=150, bbox_inches='tight')\n",
    "    print(\"✓ Gráfico guardado en: cv_results_smote_top.png\")\n",
    "    plt.close()\n",
    "else:\n",
    "    print(\"No hay resultados disponibles para graficar.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b49bb2",
   "metadata": {},
   "source": [
    "## Parte Adicional del Proyecto: Posibles Mejoras"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
