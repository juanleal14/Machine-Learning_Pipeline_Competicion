{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2308f556",
   "metadata": {},
   "source": [
    "# Report Pr√°ctica Predicci√≥n Abandono"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21005b5a",
   "metadata": {},
   "source": [
    "___________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34363eb5",
   "metadata": {},
   "source": [
    "En las siguientes celdas adjunto el c√≥digo que he usado para entrenar el m√≥delo (Gradient Boosting) con el que he obtenido los mejores resultados en balanced accuracy. No obstante, ha habido muchas m√°s fases en este proyecto en las que el c√≥digo no resultaba as√≠. \n",
    "\n",
    "Debajo de las conclusiones y resultados podr√° encontrar las diferentes pruebas tanto de modelos como par√°metros o limpieza/preprocesado que se han hecho"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272267d0",
   "metadata": {},
   "source": [
    "___________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71a7e2f",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "996d720b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "# Preprocesado\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from imblearn.over_sampling import SMOTE, BorderlineSMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "\n",
    "# Prueba de Modelos\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier, AdaBoostClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "# Evaluacion\n",
    "from sklearn.metrics import (balanced_accuracy_score, classification_report,\n",
    "                              confusion_matrix, roc_auc_score, accuracy_score,\n",
    "                              precision_score, recall_score, f1_score)\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "\n",
    "# Fijamos Semilla\n",
    "random.seed(100473223)\n",
    "np.random.seed(100473223)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a61ed0e",
   "metadata": {},
   "source": [
    "### Clase de Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "42427e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureEngineer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Crea features derivadas para capturar patrones no lineales\"\"\"\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        \n",
    "        # Evitar divisi√≥n por cero\n",
    "        def safe_divide(a, b):\n",
    "            return np.where(b != 0, a / b, 0)\n",
    "        \n",
    "        # Estabilidad laboral\n",
    "        X['Years_per_Company_Ratio'] = safe_divide(\n",
    "            X['Total Active Years'], \n",
    "            X['Number of Other Companies'] + 1\n",
    "        )\n",
    "        \n",
    "        # Retraso en promoci√≥n\n",
    "        X['Promotion_Lag'] = X['Years at Current Company'] - X['Years Since Last Promotion']\n",
    "        \n",
    "        # Ingreso por a√±o de experiencia\n",
    "        X['Income_per_Year'] = safe_divide(\n",
    "            X['Yearly Income'], \n",
    "            X['Total Active Years'] + 1\n",
    "        )\n",
    "        \n",
    "        # Estabilidad con manager actual\n",
    "        X['Manager_Stability'] = safe_divide(\n",
    "            X['Years with Current Manager'], \n",
    "            X['Years at Current Company'] + 1\n",
    "        )\n",
    "        \n",
    "        # Satisfacci√≥n general (promedio de satisfacciones)\n",
    "        satisfaction_cols = ['Job Satisfaction', 'Environment Satisfaction', \n",
    "                            'Work Life Balance Satisfaction']\n",
    "        \n",
    "        # Manejar valores faltantes temporalmente para el c√°lculo\n",
    "        X['Overall_Satisfaction'] = X[satisfaction_cols].mean(axis=1, skipna=True)\n",
    "        \n",
    "        # Baja satisfacci√≥n general\n",
    "        X['Low_Satisfaction'] = (X['Overall_Satisfaction'] < 3).astype(int)\n",
    "        \n",
    "        # Empleado reci√©n contratado\n",
    "        X['Recent_Hire'] = (X['Years at Current Company'] < 2).astype(int)\n",
    "        \n",
    "        # Promoci√≥n atrasada\n",
    "        X['Overdue_Promotion'] = (X['Years Since Last Promotion'] > 3).astype(int)\n",
    "        \n",
    "        # Commute largo (si la columna existe)\n",
    "        if 'Miles from Home to Work' in X.columns:\n",
    "            X['Long_Commute'] = (X['Miles from Home to Work'] > 20).astype(int)\n",
    "        \n",
    "        # Edad vs. Nivel de trabajo (senior joven o junior viejo = se√±al)\n",
    "        X['Age_x_JobLevel'] = X['Age'] * pd.factorize(X.get('Job Level', pd.Series([0]*len(X))))[0]\n",
    "        \n",
    "        # Satisfacci√≥n baja + salario bajo = alto riesgo\n",
    "        X['LowSat_LowIncome'] = (\n",
    "            (X['Overall_Satisfaction'] < 3) & \n",
    "            (X['Yearly Income'] < X['Yearly Income'].median())\n",
    "        ).astype(int)\n",
    "        \n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7203e313",
   "metadata": {},
   "source": [
    "### 1. Carga y Exploraci√≥n de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d55ff778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dimensiones del dataset: (3528, 27)\n",
      "\n",
      "Distribuci√≥n de la clase objetivo (Attrition):\n",
      "Attrition\n",
      "No     2956\n",
      "Yes     572\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Porcentaje de Attrition:\n",
      "Attrition\n",
      "No     83.786848\n",
      "Yes    16.213152\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "‚ö† Ratio de desbalanceo: 5.17:1\n",
      "Clase minoritaria (Yes): 16.2%\n",
      "‚Üí Se usar√° SMOTE en el pipeline de entrenamiento y CV.\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('train.csv')\n",
    "\n",
    "print(f\"\\nDimensiones del dataset: {data.shape}\")\n",
    "print(f\"\\nDistribuci√≥n de la clase objetivo (Attrition):\")\n",
    "print(data['Attrition'].value_counts())\n",
    "attrition_dist = data['Attrition'].value_counts(normalize=True) * 100\n",
    "print(f\"\\nPorcentaje de Attrition:\\n{attrition_dist}\")\n",
    "\n",
    "# Ratio de desbalanceo (solo informativo)\n",
    "class_counts = data['Attrition'].value_counts()\n",
    "imbalance_ratio = class_counts['No'] / class_counts['Yes']\n",
    "print(f\"\\n‚ö† Ratio de desbalanceo: {imbalance_ratio:.2f}:1\")\n",
    "print(f\"Clase minoritaria (Yes): {attrition_dist['Yes']:.1f}%\")\n",
    "print(\"‚Üí Se usar√° SMOTE en el pipeline de entrenamiento y CV.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233cdf0e",
   "metadata": {},
   "source": [
    "### 2. Divisi√≥n en Entrenamiento y Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "465403be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Conjunto de entrenamiento: 2822 instancias\n",
      "Conjunto de test: 706 instancias\n",
      "\n",
      "Distribuci√≥n en entrenamiento:\n",
      "Attrition\n",
      "0    2364\n",
      "1     458\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Distribuci√≥n en test:\n",
      "Attrition\n",
      "0    592\n",
      "1    114\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X = data.drop(['Attrition', 'ID'], axis=1)\n",
    "y = data['Attrition'].map({'No': 0, 'Yes': 1})\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, shuffle=True, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"\\nConjunto de entrenamiento: {X_train.shape[0]} instancias\")\n",
    "print(f\"Conjunto de test: {X_test.shape[0]} instancias\")\n",
    "print(f\"\\nDistribuci√≥n en entrenamiento:\\n{y_train.value_counts()}\")\n",
    "print(f\"\\nDistribuci√≥n en test:\\n{y_test.value_counts()}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa565ec2",
   "metadata": {},
   "source": [
    "### 3. Preprocesado de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4c39f494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Columnas num√©ricas: 15\n",
      "Columnas ordinales: 3\n",
      "Columnas categ√≥ricas: 7\n",
      "\n",
      "==================================================\n",
      "AN√ÅLISIS DE VALORES FALTANTES\n",
      "==================================================\n",
      "                       Columna  Valores_Faltantes  Porcentaje\n",
      "        Amount of Stock Option               1213   42.983700\n",
      "       Miles from Home to Work                572   20.269313\n",
      "                Marital Status                419   14.847626\n",
      "Work Life Balance Satisfaction                168    5.953225\n",
      "              Job Satisfaction                154    5.457123\n",
      "      Environment Satisfaction                139    4.925585\n",
      "     Number of Other Companies                 11    0.389794\n",
      "            Total Active Years                  4    0.141743\n",
      "\n",
      "Total de columnas con valores faltantes: 8\n",
      "\n",
      "‚ö† Eliminando columnas con >30% de valores faltantes: ['Amount of Stock Option']\n",
      "‚úì Columnas eliminadas. Nuevas dimensiones: (2822, 24)\n"
     ]
    }
   ],
   "source": [
    "numerical_cols = [\n",
    "    'Age', 'Miles from Home to Work', 'Yearly Income', 'Absences per Year',\n",
    "    'Performance Rating', 'Job Satisfaction', 'Environment Satisfaction',\n",
    "    'Work Life Balance Satisfaction', 'Last Salary Increase (%)',\n",
    "    'Number of Training Sessions Last Year', 'Number of Other Companies',\n",
    "    'Total Active Years', 'Years at Current Company',\n",
    "    'Years Since Last Promotion', 'Years with Current Manager'\n",
    "]\n",
    "\n",
    "ordinal_cols = {\n",
    "    'Education Level': [['High School', 'College', 'Bachelor', 'Master', 'Doctor']],\n",
    "    'Job Level': [['Entry Level', 'Mid Level', 'Senior Level', 'Director', 'Executive']],\n",
    "    'Job Involvement': [['Low', 'Medium', 'High', 'Very High']]\n",
    "}\n",
    "\n",
    "categorical_cols = [\n",
    "    'Gender', 'Marital Status', 'Education Field', 'Department Name',\n",
    "    'Job Role Name', 'Business Travel Frequency', 'Amount of Stock Option'\n",
    "]\n",
    "\n",
    "print(f\"\\nColumnas num√©ricas: {len(numerical_cols)}\")\n",
    "print(f\"Columnas ordinales: {len(ordinal_cols)}\")\n",
    "print(f\"Columnas categ√≥ricas: {len(categorical_cols)}\")\n",
    "\n",
    "\n",
    "# An√°lisis de valores faltantes\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"AN√ÅLISIS DE VALORES FALTANTES\")\n",
    "print(\"=\"*50)\n",
    "missing_values = X_train.isnull().sum()\n",
    "missing_percent = (missing_values / len(X_train)) * 100\n",
    "missing_df = pd.DataFrame({\n",
    "    'Columna': missing_values.index,\n",
    "    'Valores_Faltantes': missing_values.values,\n",
    "    'Porcentaje': missing_percent.values\n",
    "})\n",
    "missing_df = missing_df[missing_df['Valores_Faltantes'] > 0].sort_values('Valores_Faltantes', ascending=False)\n",
    "if len(missing_df) > 0:\n",
    "    print(missing_df.to_string(index=False))\n",
    "else:\n",
    "    print(\"‚úì No hay valores faltantes en el dataset\")\n",
    "print(f\"\\nTotal de columnas con valores faltantes: {len(missing_df)}\")\n",
    "    \n",
    "# Eliminar columnas con >30% de valores faltantes\n",
    "cols_to_drop = missing_df[missing_df['Porcentaje'] > 30]['Columna'].tolist()\n",
    "if cols_to_drop:\n",
    "    print(f\"\\n‚ö† Eliminando columnas con >30% de valores faltantes: {cols_to_drop}\")\n",
    "    X_train = X_train.drop(columns=cols_to_drop)\n",
    "    X_test = X_test.drop(columns=cols_to_drop)\n",
    "    \n",
    "    # Actualizar listas de columnas\n",
    "    numerical_cols = [col for col in numerical_cols if col not in cols_to_drop]\n",
    "    categorical_cols = [col for col in categorical_cols if col not in cols_to_drop]\n",
    "    ordinal_cols = {k: v for k, v in ordinal_cols.items() if k not in cols_to_drop}\n",
    "    \n",
    "    print(f\"‚úì Columnas eliminadas. Nuevas dimensiones: {X_train.shape}\")\n",
    "else:\n",
    "    print(\"‚úì No hay valores faltantes en el dataset\")\n",
    "# === PREPROCESADO ===\n",
    "\n",
    "# 1) Transformadores por tipo de columna\n",
    "num_transformer = ImbPipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Un pipeline ordinal por cada columna ordinal (imputar + codificar)\n",
    "ord_transformers = []\n",
    "for col, categories in ordinal_cols.items():\n",
    "    ord_transformers.append((\n",
    "        f'ord_{col}',\n",
    "        ImbPipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "            ('encoder', OrdinalEncoder(\n",
    "                categories=categories,\n",
    "                handle_unknown='use_encoded_value',\n",
    "                unknown_value=-1\n",
    "            ))        \n",
    "        ]),\n",
    "        [col]\n",
    "    ))\n",
    "\n",
    "cat_transformer = ImbPipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(sparse_output=False, handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# 2) Un √∫nico ColumnTransformer como preprocesador\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', num_transformer, numerical_cols),\n",
    "        *ord_transformers,\n",
    "        ('cat', cat_transformer, categorical_cols)\n",
    "    ],\n",
    "    remainder='drop',\n",
    "    verbose_feature_names_out=False\n",
    ")\n",
    "\n",
    "# 3) Pipeline FINAL con SMOTE (Sin nested Pipeline en pasos intermedios)\n",
    "# MEJORA #2: Usar BorderlineSMOTE en lugar de SMOTE\n",
    "ml_pipe_improved = ImbPipeline(steps=[\n",
    "    ('feature_engineer', FeatureEngineer()),  # \"Juego de features\"\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('smote', BorderlineSMOTE(random_state=42, kind='borderline-1')),  # Tiene en cuenta los bordes\n",
    "    ('classifier', LogisticRegression())  # placeholder\n",
    "])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9561706a",
   "metadata": {},
   "source": [
    "### Modelos a probar: \n",
    "(Las pruebas descartadas est√°n incluidas debajo de los resultados oficiales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6bb5ddfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid= [\n",
    "    # Gradient Boosting - Excelente para balanced accuracy\n",
    "    {\n",
    "        'classifier': [GradientBoostingClassifier(random_state=42)],\n",
    "        'classifier__n_estimators': [600],\n",
    "        'classifier__learning_rate': [0.15],\n",
    "        'classifier__max_depth': [5],\n",
    "        'classifier__subsample': [0.9],\n",
    "        'classifier__min_samples_leaf': [7]\n",
    "    }\n",
    "]\n",
    "# La mejor combinaci√≥n ser√° (en mi experiencia): {'classifier': GradientBoostingClassifier(random_state=42), 'classifier__learning_rate': 0.15, 'classifier__max_depth': 5, 'classifier__min_samples_leaf': 7, 'classifier__n_estimators': 600, 'classifier__subsample': 0.9}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241e3d0f",
   "metadata": {},
   "source": [
    "### Inicializamos la b√∫squeda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f25b0afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iniciando b√∫squeda CON SMOTE integrado (CV estratificada)...\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì B√∫squeda CON SMOTE completada!\n",
      "\n",
      "Mejor modelo CON SMOTE:\n",
      "  Clasificador: GradientBoostingClassifier\n",
      "  Balanced Accuracy (CV): 0.9021\n",
      "Threshold por defecto (0.5): 1.0000\n",
      "Threshold √≥ptimo encontrado: 0.100\n",
      "Balanced Accuracy con threshold √≥ptimo: 1.0000\n",
      "Mejora: +0.0000\n"
     ]
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "search_smote = GridSearchCV(\n",
    "    estimator=ml_pipe_improved,   # ImbPipeline\n",
    "    param_grid=grid,\n",
    "    scoring='balanced_accuracy',\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    error_score='raise',\n",
    "    verbose = 1,\n",
    ")\n",
    "\n",
    "\n",
    "print(\"\\nIniciando b√∫squeda CON SMOTE integrado (CV estratificada)...\")\n",
    "search_smote.fit(X_train, y_train)\n",
    "print(\"‚úì B√∫squeda CON SMOTE completada!\")\n",
    "\n",
    "print(f\"\\nMejor modelo CON SMOTE:\")\n",
    "print(f\"  Clasificador: {search_smote.best_estimator_['classifier'].__class__.__name__}\")\n",
    "print(f\"  Balanced Accuracy (CV): {search_smote.best_score_:.4f}\")\n",
    "\n",
    "best_model = search_smote.best_estimator_\n",
    "\n",
    "def find_optimal_threshold(model, X_val, y_val):\n",
    "    \"\"\"Encuentra el threshold √≥ptimo para balanced accuracy\"\"\"\n",
    "    y_proba = model.predict_proba(X_val)[:, 1]\n",
    "    \n",
    "    thresholds = np.arange(0.1, 0.9, 0.01)\n",
    "    scores = []\n",
    "    \n",
    "    for thresh in thresholds:\n",
    "        y_pred = (y_proba >= thresh).astype(int)\n",
    "        score = balanced_accuracy_score(y_val, y_pred)\n",
    "        scores.append(score)\n",
    "    \n",
    "    optimal_idx = np.argmax(scores)\n",
    "    optimal_threshold = thresholds[optimal_idx]\n",
    "    optimal_score = scores[optimal_idx]\n",
    "    \n",
    "    print(f\"Threshold por defecto (0.5): {balanced_accuracy_score(y_val, (y_proba >= 0.5).astype(int)):.4f}\")\n",
    "    print(f\"Threshold √≥ptimo encontrado: {optimal_threshold:.3f}\")\n",
    "    print(f\"Balanced Accuracy con threshold √≥ptimo: {optimal_score:.4f}\")\n",
    "    print(f\"Mejora: +{(optimal_score - balanced_accuracy_score(y_val, (y_proba >= 0.5).astype(int))):.4f}\")\n",
    "    \n",
    "    return optimal_threshold\n",
    "\n",
    "# Encontrar threshold √≥ptimo en train\n",
    "optimal_threshold = find_optimal_threshold(best_model, X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8089890",
   "metadata": {},
   "source": [
    "### Mejor Modelo:\n",
    "{'classifier': GradientBoostingClassifier(random_state=42), 'classifier__learning_rate': 0.15, 'classifier__max_depth': 5, 'classifier__min_samples_leaf': 7, 'classifier__n_estimators': 600, 'classifier__subsample': 0.9}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4afccfea",
   "metadata": {},
   "source": [
    "### 5. Evaluaci√≥n en test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003e27d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä COMPARACI√ìN DE RESULTADOS:\n",
      "          M√©trica  Threshold 0.5  Threshold √ìptimo    Mejora\n",
      "Balanced Accuracy       0.949384          0.965238  0.015855\n",
      "         Accuracy       0.974504          0.977337  0.002833\n",
      "  Precision (Yes)       0.928571          0.915254 -0.013317\n",
      "     Recall (Yes)       0.912281          0.947368  0.035088\n",
      "   F1-Score (Yes)       0.920354          0.931034  0.010681\n",
      "          AUC-ROC       0.976307          0.976307  0.000000\n",
      "\n",
      "üéâ Balanced Accuracy Final: 0.9652\n",
      "   Mejora vs threshold 0.5: +0.0159\n",
      "\n",
      "üìã Matriz de Confusi√≥n (Threshold √ìptimo):\n",
      "[[582  10]\n",
      " [  6 108]]\n",
      "  TP=108, FP=10, FN=6, TN=582\n",
      "\n",
      "üìÑ REPORTE DE CLASIFICACI√ìN (Threshold √ìptimo):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "No Attrition       0.99      0.98      0.99       592\n",
      "   Attrition       0.92      0.95      0.93       114\n",
      "\n",
      "    accuracy                           0.98       706\n",
      "   macro avg       0.95      0.97      0.96       706\n",
      "weighted avg       0.98      0.98      0.98       706\n",
      "\n",
      "\n",
      "================================================================================\n",
      "6. GUARDADO DE MODELO Y RESULTADOS\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Predicciones con threshold por defecto (0.5)\n",
    "y_pred_default = best_model.predict(X_test)\n",
    "y_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Predicciones con threshold √≥ptimo\n",
    "y_pred_optimal = (y_proba >= optimal_threshold).astype(int)\n",
    "\n",
    "# M√©tricas con threshold por defecto\n",
    "ba_default = balanced_accuracy_score(y_test, y_pred_default)\n",
    "acc_default = accuracy_score(y_test, y_pred_default)\n",
    "prec_default = precision_score(y_test, y_pred_default)\n",
    "rec_default = recall_score(y_test, y_pred_default)\n",
    "f1_default = f1_score(y_test, y_pred_default)\n",
    "\n",
    "# M√©tricas con threshold √≥ptimo\n",
    "ba_optimal = balanced_accuracy_score(y_test, y_pred_optimal)\n",
    "acc_optimal = accuracy_score(y_test, y_pred_optimal)\n",
    "prec_optimal = precision_score(y_test, y_pred_optimal)\n",
    "rec_optimal = recall_score(y_test, y_pred_optimal)\n",
    "f1_optimal = f1_score(y_test, y_pred_optimal)\n",
    "auc = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "# Comparaci√≥n de m√©tricas\n",
    "metrics_comparison = pd.DataFrame({\n",
    "    'M√©trica': ['Balanced Accuracy', 'Accuracy', 'Precision (Yes)', 'Recall (Yes)', 'F1-Score (Yes)', 'AUC-ROC'],\n",
    "    'Threshold 0.5': [ba_default, acc_default, prec_default, rec_default, f1_default, auc],\n",
    "    'Threshold √ìptimo': [ba_optimal, acc_optimal, prec_optimal, rec_optimal, f1_optimal, auc],\n",
    "    'Mejora': [\n",
    "        ba_optimal - ba_default,\n",
    "        acc_optimal - acc_default,\n",
    "        prec_optimal - prec_default,\n",
    "        rec_optimal - rec_default,\n",
    "        f1_optimal - f1_default,\n",
    "        0\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\nüìä COMPARACI√ìN DE RESULTADOS:\")\n",
    "print(metrics_comparison.to_string(index=False))\n",
    "\n",
    "print(f\"\\nüéâ Balanced Accuracy Final: {ba_optimal:.4f}\")\n",
    "print(f\"   Mejora vs threshold 0.5: +{(ba_optimal - ba_default):.4f}\")\n",
    "\n",
    "# Matriz de confusi√≥n con threshold √≥ptimo\n",
    "cm = confusion_matrix(y_test, y_pred_optimal)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "print(\"\\nüìã Matriz de Confusi√≥n (Threshold √ìptimo):\")\n",
    "print(cm)\n",
    "print(f\"  TP={tp}, FP={fp}, FN={fn}, TN={tn}\")\n",
    "\n",
    "print(\"\\nüìÑ REPORTE DE CLASIFICACI√ìN (Threshold √ìptimo):\")\n",
    "print(classification_report(y_test, y_pred_optimal, target_names=['No Attrition', 'Attrition']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28cfad2c",
   "metadata": {},
   "source": [
    "### 6. Guardar Modelo y Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a388ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Modelo mejorado guardado: best_model_improved.pkl\n",
      "  (incluye threshold √≥ptimo: 0.100)\n"
     ]
    }
   ],
   "source": [
    "model_data = {\n",
    "    'model': best_model,\n",
    "    'optimal_threshold': optimal_threshold,\n",
    "    'feature_names': X_train.columns.tolist()\n",
    "}\n",
    "with open('best_model_improved.pkl', 'wb') as f:\n",
    "    pkl.dump(model_data, f)\n",
    "print(\"‚úì Modelo mejorado guardado: best_model_improved.pkl\")\n",
    "print(f\"  (incluye threshold √≥ptimo: {optimal_threshold:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb713ea5",
   "metadata": {},
   "source": [
    "## Parte Adicional del Proyecto: Intentos Fallidos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98be91fd",
   "metadata": {},
   "source": [
    "### Pruebas de Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a5cf0a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid= [\n",
    "    # 1) Logistic Regression (l1/l2, con y sin class_weight, distintos solvers)\n",
    "{\n",
    "    'classifier': [LogisticRegression(random_state=42, max_iter=2000)],\n",
    "    'classifier__penalty': ['l2', 'l1'],\n",
    "    'classifier__solver': ['liblinear', 'saga'],   # l1 soportado por liblinear/saga\n",
    "    'classifier__C': [0.1, 1, 3, 10],\n",
    "    'classifier__class_weight': ['balanced'],\n",
    "},\n",
    "   ## 2) √Årbol de decisi√≥n (m√°s profundo, min_samples_* y max_features)\n",
    "{\n",
    "    'classifier': [DecisionTreeClassifier(random_state=42)],\n",
    "    'classifier__criterion': ['gini', 'entropy', 'log_loss'],\n",
    "    'classifier__max_depth': [None, 5, 10, 20],\n",
    "    'classifier__min_samples_split': [2, 5, 10],\n",
    "    'classifier__min_samples_leaf': [1, 2, 5],\n",
    "    'classifier__class_weight': ['balanced']\n",
    "},\n",
    "   ## 3) KNN (m√°s vecinos, distancia y leaf_size)\n",
    "{\n",
    "    'classifier': [KNeighborsClassifier()],\n",
    "    'classifier__n_neighbors': [3, 5, 7, 9, 11, 15],\n",
    "    'classifier__weights': ['uniform', 'distance'],\n",
    "    'classifier__p': [1, 2],                # manhattan / euclid\n",
    "    'classifier__leaf_size': [15, 30, 45]\n",
    "},\n",
    "  # Random Forest optimizado para balanced accuracy\n",
    "   ## 5) Random Forest (m√°s n_estimators, max_features, bootstrap)\n",
    "{\n",
    "    'classifier': [RandomForestClassifier(random_state=42)],\n",
    "    'classifier__n_estimators': [100, 300, 500],\n",
    "    'classifier__criterion': ['gini', 'entropy'],\n",
    "    'classifier__max_depth': [None, 10, 20],\n",
    "    'classifier__min_samples_split': [2, 5, 10],\n",
    "    'classifier__min_samples_leaf': [1, 2, 4],\n",
    "    'classifier__class_weight': ['balanced']\n",
    "},\n",
    "   ## 6) Gradient Boosting\n",
    "{\n",
    "    'classifier': [GradientBoostingClassifier(random_state=42)],\n",
    "    'classifier__n_estimators': [100, 200, 400, 600],\n",
    "    'classifier__learning_rate': [0.02, 0.05, 0.1, 0.2],\n",
    "    'classifier__max_depth': [2, 3, 5],\n",
    "    'classifier__min_samples_leaf': [1, 2, 5],\n",
    "    'classifier__subsample': [0.6, 0.8, 0.9, 1.0]\n",
    "},\n",
    "  ## 7) Extra Trees\n",
    "{\n",
    "    'classifier': [ExtraTreesClassifier(random_state=42)],\n",
    "    'classifier__n_estimators': [200, 500],\n",
    "    'classifier__criterion': ['gini', 'entropy', 'log_loss'],\n",
    "    'classifier__max_depth': [None, 10, 20],\n",
    "    'classifier__min_samples_split': [2, 5, 10],\n",
    "    'classifier__min_samples_leaf': [1, 2, 4],\n",
    "    'classifier__class_weight': ['balanced']\n",
    "},\n",
    "  ## 8) AdaBoost\n",
    "{\n",
    "   'classifier': [AdaBoostClassifier(\n",
    "       random_state=42,\n",
    "       estimator=DecisionTreeClassifier(random_state=42)\n",
    "   )],\n",
    "   'classifier__algorithm': ['SAMME'],\n",
    "   'classifier__n_estimators': [100, 300],\n",
    "   'classifier__learning_rate': [0.1, 0.2, 0.5],\n",
    "   'classifier__estimator__max_depth': [1, 2, 3],\n",
    "   'classifier__estimator__min_samples_leaf': [1, 2, 5]\n",
    "},\n",
    "  # multi-layer Perceptron\n",
    "  {\n",
    "      'classifier': [MLPClassifier(random_state=42, max_iter=1000)],\n",
    "      'classifier__hidden_layer_sizes': [(50,), (100,), (50, 50)],\n",
    "      'classifier__activation': ['relu', 'tanh'],\n",
    "      'classifier__alpha': [0.001, 0.01]\n",
    "  }\n",
    "]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fa0333",
   "metadata": {},
   "source": [
    "### Plot de los resultados con varios modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "95fa47f3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ml_pipe_smote' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 16\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 7. RESUMEN COMPLETO DE LA B√öSQUEDA + PLOT\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m#    verbose = 1,\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m#)\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RandomizedSearchCV\n\u001b[1;32m     15\u001b[0m search \u001b[38;5;241m=\u001b[39m RandomizedSearchCV(\n\u001b[0;32m---> 16\u001b[0m     estimator\u001b[38;5;241m=\u001b[39m\u001b[43mml_pipe_smote\u001b[49m,\n\u001b[1;32m     17\u001b[0m     param_distributions\u001b[38;5;241m=\u001b[39mgrid,\n\u001b[1;32m     18\u001b[0m     n_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m,  \u001b[38;5;66;03m# Prueba 100 combinaciones aleatorias\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbalanced_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     20\u001b[0m     cv\u001b[38;5;241m=\u001b[39mcv,\n\u001b[1;32m     21\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     22\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     23\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m\n\u001b[1;32m     24\u001b[0m )\n\u001b[1;32m     25\u001b[0m search_smote\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m     26\u001b[0m cv_results_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(search_smote\u001b[38;5;241m.\u001b[39mcv_results_)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ml_pipe_smote' is not defined"
     ]
    }
   ],
   "source": [
    "# 7. RESUMEN COMPLETO DE LA B√öSQUEDA + PLOT\n",
    "\n",
    "#cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "#search_smote = GridSearchCV(\n",
    "#    estimator=ml_pipe_smote,   # ImbPipeline\n",
    "#    param_grid=grid,\n",
    "#    scoring='balanced_accuracy',\n",
    "#    cv=cv,\n",
    "#    n_jobs=-1,\n",
    "#    error_score='raise',\n",
    "#    verbose = 1,\n",
    "#)\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "search = RandomizedSearchCV(\n",
    "    estimator=ml_pipe_smote,\n",
    "    param_distributions=grid,\n",
    "    n_iter=100,  # Prueba 100 combinaciones aleatorias\n",
    "    scoring='balanced_accuracy',\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    random_state=42\n",
    ")\n",
    "search_smote.fit(X_train, y_train)\n",
    "cv_results_df = pd.DataFrame(search_smote.cv_results_)\n",
    "score_cols = [\n",
    "    col for col in cv_results_df.columns\n",
    "    if col.startswith('split') and col.endswith('_test_score')\n",
    "]\n",
    "summary_cols = ['params', 'mean_test_score', 'std_test_score', 'rank_test_score'] + score_cols\n",
    "cv_results_summary = cv_results_df[summary_cols].copy()\n",
    "cv_results_summary = cv_results_summary.sort_values('rank_test_score')\n",
    "\n",
    "def _format_params(params: dict) -> str:\n",
    "    return ', '.join(f\"{key}={value}\" for key, value in params.items())\n",
    "\n",
    "cv_results_summary['params'] = cv_results_summary['params'].apply(_format_params)\n",
    "cv_results_summary = cv_results_summary.rename(columns={\n",
    "    'params': 'Par√°metros',\n",
    "    'mean_test_score': 'Balanced Accuracy media',\n",
    "    'std_test_score': 'Desviaci√≥n est√°ndar',\n",
    "    'rank_test_score': 'Ranking'\n",
    "})\n",
    "\n",
    "print(\"\\nResultados completos de la b√∫squeda (ordenados por ranking):\")\n",
    "print(cv_results_summary.to_string(index=False))\n",
    "\n",
    "cv_results_summary.to_csv('cv_results_smote.csv', index=False)\n",
    "print(\"\\n‚úì Resultados de la b√∫squeda guardados en: cv_results_smote.csv\")\n",
    "\n",
    "if len(cv_results_summary) > 0:\n",
    "    top_n = min(10, len(cv_results_summary))\n",
    "    top_results = cv_results_summary.head(top_n)\n",
    "    plt.figure(figsize=(12, max(6, top_n * 0.5)))\n",
    "    sns.barplot(\n",
    "        data=top_results,\n",
    "        x='Balanced Accuracy media',\n",
    "        y='Par√°metros',\n",
    "        palette='viridis'\n",
    "    )\n",
    "    plt.title(f'Mejores {top_n} combinaciones - Balanced Accuracy (CV)')\n",
    "    plt.xlabel('Balanced Accuracy media (CV)')\n",
    "    plt.ylabel('Par√°metros')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('cv_results_smote_top.png', dpi=150, bbox_inches='tight')\n",
    "    print(\"‚úì Gr√°fico guardado en: cv_results_smote_top.png\")\n",
    "    plt.close()\n",
    "else:\n",
    "    print(\"No hay resultados disponibles para graficar.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b49bb2",
   "metadata": {},
   "source": [
    "## Parte Adicional del Proyecto: Posibles Mejoras"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
